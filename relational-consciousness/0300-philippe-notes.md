# Notes from Philippe

One question I feel is not the best question.

You've guessed it... It's "What is consciousness?"

I think that, as the primary question we ask, it is hurting our ability to form a better world model. I find asking "When do two systems treat each other as conscious?" is a better starting point. From there we would likely end up on a definition for _cross-consciousness_ or _relational consciousness_. We could then go back to the original question and define consciousness as: "X is conscious iif X is relationally conscious with X".

The advantage of that approach is that it lets us consider systems as black boxes. It is appealing to me because I am convinced we would grant consciousness to an alien civilization based on their "black box behavior" not based on how their brain operates.

If I had to take an initial stab at it, I would define _relational consciousness_ as such:
Two systems have _relational consciousness_ if they adopt, in many different environments, a series of behaviors toward each other that show an awareness of the other's inner drive. (eg. behavior of care, of strategic aggression, etc.)

It needs a lot of refinement, for example "many different environments" and "a series of behaviors" are meant to (soft-)exclude things like Eliza. However, without more precision, it's unclear how well they succeed. Intuitively, though, starting with _"What is relational consciousness?"_ seems to lead to a better way to structure our conceptual graph than the original question.

More generally (and following our conversation) my new test for _is concept X real or imagined/illusory_ is the following. If I imagine a scientist-outside-the-cosmos, would they observe X as an emergent phenomena and would they be tempted to name it?

_Relational consciousness?_ Totally! This thing appears between all sorts of systems! It is predictive of their behavior and a very useful concept.

_Consciousness?_ Yeah, it's pretty natural to define this. But it probably needs to be further qualified to be predictive. For example, we could argue that some unicellular organisms are relationally conscious, and therefore conscious, but they are not relationally conscious to humans. (So there seems to be consciousness classes.)

_Qualia?_ Nah, I don't think a scientist-outside-the-cosmos would need this except as "this strange word humans use to talk about something, but I can't figure out what that is". (My intuition? It's the key in an attention model. But I'm getting very esoteric. )

_Life? Aliveness?_ Yeah. I think that's the quality that would make the scientist-outside-the-cosmos fascinated by the simulation... Even though they probably couldn't define it precisely apart from "it's beautiful!" (And even here, on earth, it is the thing that is driving the enthusiasm of the whole artificial life community.)
